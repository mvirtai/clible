# AnalysisTracker - Logiikka ja Toteutus

## üìö Sis√§llysluettelo

1. [Yleiskatsaus](#yleiskatsaus)
2. [Arkkitehtuuri](#arkkitehtuuri)
3. [Metodien Logiikka](#metodien-logiikka)
4. [Tietokantaskeema](#tietokantaskeema)
5. [K√§ytt√∂esimerkit](#k√§ytt√∂esimerkit)
6. [Debuggaus ja Troubleshooting](#debuggaus-ja-troubleshooting)

---

## Yleiskatsaus

`AnalysisTracker` on luokka, joka tallentaa analyysitulokset tietokantaan tulevaa k√§ytt√∂√§ varten. Sen avulla voidaan:

- üíæ **Tallentaa** analyysitulokset (sanafrekvenssit, fraasit)
- üìä **Hakea** analyysien historiaa suodattimilla
- üîç **Tarkastella** yksitt√§isi√§ analyysej√§ yksityiskohtaisesti
- ‚öñÔ∏è **Vertailla** kahta analyysi√§ kesken√§√§n

### Keskeiset K√§sitteet

**Analysis History** = Metadata (milloin, kuka, mit√§, kuinka paljon)  
**Analysis Results** = Varsinaiset tulokset (JSON-muodossa)  
**Scope** = Analyysin laajuus (yksitt√§inen query, session, kirja, jne.)

---

## Arkkitehtuuri

### Luokan Rakenne

```python
class AnalysisTracker:
    def __init__(self, user_id, session_id, db_path):
        self.user_id = user_id         # Kuka analyysej√§ tekee
        self.session_id = session_id   # Miss√§ sessiossa (valinnainen)
        self.db_path = db_path         # Mihin tietokantaan (testaus)
```

### Dependency Injection Pattern

```python
def _get_db(self):
    """Palauttaa QueryDB-instanssin oikealla polulla"""
    if self.db_path is None:
        return QueryDB()              # Tuotanto: default database
    return QueryDB(self.db_path)      # Testit: temporary database
```

**Miksi t√§m√§ on t√§rke√§√§?**

- Testit k√§ytt√§v√§t v√§liaikaista tietokantaa (`/tmp/...`)
- Tuotanto k√§ytt√§√§ oikeaa tietokantaa (`data/clible.db`)
- Sama koodi toimii molemmissa ymp√§rist√∂iss√§

---

## Metodien Logiikka

### 1. `save_word_frequency_analysis()`

**Tarkoitus:** Tallentaa sanafrekvenssien analyysin

**Vaiheet:**

```python
# VAIHE 1: Luo uniikki ID
analysis_id = uuid.uuid4().hex[:8]  # Esim: "a3b4c5d6"

# VAIHE 2: Tallenna metadata
INSERT INTO analysis_history (
    id, user_id, session_id,
    analysis_type,      # "word_frequency"
    scope_type,         # "query", "session", "book", "multi_query"
    scope_details,      # JSON: {"query_id": "abc123"}
    verse_count         # 25
)

# VAIHE 3: Tallenna word_freq tulokset
INSERT INTO analysis_results (
    id,                 # Uusi UUID
    analysis_id,        # Linkki historiaan
    result_type,        # "word_freq"
    result_data,        # JSON: [["jesus", 120], ["lord", 85], ...]
    chart_path          # "data/charts/..."
)

# VAIHE 4: Tallenna vocab_stats tulokset
INSERT INTO analysis_results (
    ...
    result_type,        # "vocab_stats"
    result_data,        # JSON: {"total_tokens": 1500, ...}
    ...
)

# VAIHE 5: Commit ja palauta ID
db.conn.commit()
return analysis_id
```

**Kriittiset kohdat:**

1. **JSON Serialisointi**

   ```python
   json.dumps(word_freq)         # list[tuple] ‚Üí string
   json.dumps(scope_details)     # dict ‚Üí string
   ```

   - **Miksi?** SQLite ei tue listoja/dictionaryja suoraan
   - Tuples muuttuvat automaattisesti listoiksi JSONissa

2. **Chart Paths** (valinnainen)
   ```python
   chart_paths.get('word_freq') if chart_paths else None
   ```
   - Jos visualisointeja ei tehty ‚Üí `None`
   - Jos tehty ‚Üí polku tiedostoon

---

### 2. `save_phrase_analysis()`

**Tarkoitus:** Tallentaa bigrammi- ja trigrammi-analyysin

**Ero word_frequency:hin:**

- `analysis_type = "phrase_analysis"` (ei "word_frequency")
- **Kaksi** result-tietuetta:
  - `result_type = "bigram"` ‚Üí bigram data
  - `result_type = "trigram"` ‚Üí trigram data

**Logiikka on muuten identtinen** ‚Üí koodi on melkein kopio `save_word_frequency_analysis()`:sta

---

### 3. `get_analysis_history()`

**Tarkoitus:** Hae analyysien metadata suodattimilla

**Dynaaminen SQL-kysely:**

```python
# Alkupiste - aina TRUE
query = "SELECT * FROM analysis_history WHERE 1=1"
params = []

# Lis√§√§ suodattimia dynaamisesti
if self.user_id:
    query += " AND user_id = ?"
    params.append(self.user_id)

if analysis_type:  # Esim: "word_frequency"
    query += " AND analysis_type = ?"
    params.append(analysis_type)

if scope_type:     # Esim: "book"
    query += " AND scope_type = ?"
    params.append(scope_type)

# J√§rjestys ja rajoitus
query += " ORDER BY created_at DESC, ROWID DESC LIMIT ?"
params.append(limit)
```

**Miksi dynaaminen?**

- K√§ytt√§j√§ voi suodattaa **tai olla suodattamatta**
- Ei tarvitse kirjoittaa 8 eri SQL-kysely√§
- Parametrit est√§v√§t SQL-injektion

**J√§rjestys:**

- `ORDER BY created_at DESC` ‚Üí Uusin ensin
- `, ROWID DESC` ‚Üí Jos sama aikaleima, viimeisin rivi ensin

**ROWID Tiebreaker:**

```
Ongelma: 3 analyysi√§ luotu 0.001s sis√§ll√§ ‚Üí sama timestamp
Ratkaisu: ROWID (rivij√§rjestysnumero) kasvaa aina
         ‚Üí Uusin rivi = suurin ROWID
```

---

### 4. `get_analysis_results()`

**Tarkoitus:** Hae yksi analyysi KAIKKINEEN (metadata + tulokset)

**SQL JOIN:**

```sql
SELECT
    h.*,                    -- Kaikki history-kent√§t
    r.result_type,          -- "word_freq", "vocab_stats"
    r.result_data,          -- JSON data
    r.chart_path            -- Polku kuvaan
FROM analysis_history h
LEFT JOIN analysis_results r ON h.id = r.analysis_id
WHERE h.id = ?
```

**LEFT JOIN?** Koska analyysill√§ voi olla 0-N tulosta (vaikka normaalisti 2)

**Tulos:** Yksi rivi per result_type:

```
| id   | user_id | analysis_type | result_type | result_data        |
|------|---------|---------------|-------------|--------------------|
| abc  | user1   | word_freq     | word_freq   | [["jesus", 120]]   |
| abc  | user1   | word_freq     | vocab_stats | {"total": 1500}    |
```

**Python-puolen logiikka:**

```python
rows = db.cur.fetchall()  # 2 rivi√§

# 1. Ota ensimm√§inen rivi ‚Üí metadata
first_row = rows[0]
analysis = {
    "id": first_row["id"],
    "user_id": first_row["user_id"],
    ...
    "results": {},        # T√§ytet√§√§n loopeissa
    "chart_paths": {}     # T√§ytet√§√§n loopeissa
}

# 2. K√§y l√§pi KAIKKI rivit ‚Üí deserialize JSON
for row in rows:
    result_type = row["result_type"]  # "word_freq" tai "vocab_stats"

    # Muuta JSON string ‚Üí Python object
    data = json.loads(row["result_data"])

    # Lis√§√§ dictionaryyn
    analysis["results"][result_type] = data

    if row["chart_path"]:
        analysis["chart_paths"][result_type] = row["chart_path"]

return analysis
```

**JSON Deserialisointi:**

```python
# Tietokannassa (string):
'[["jesus", 120], ["lord", 85]]'

# Python-objektina (list):
[["jesus", 120], ["lord", 85]]
```

---

### 5. `compare_analyses()`

**Tarkoitus:** Vertaa kahta sanafrekvenssien analyysi√§

**Vaiheet:**

```python
# 1. Hae molemmat analyysit
a1 = self.get_analysis_results(id1)
a2 = self.get_analysis_results(id2)

# 2. Tarkista ett√§ l√∂ytyiv√§t
if not a1 or not a2:
    return None

# 3. Muuta listat ‚Üí dictionaries
words_1 = dict(a1["results"]["word_freq"])
# {"jesus": 120, "lord": 85, "god": 65}

words_2 = dict(a2["results"]["word_freq"])
# {"jesus": 150, "love": 60, "peace": 40}
```

**Set-operaatiot:**

```python
# Yhteiset sanat (intersection)
common = set(words_1.keys()) & set(words_2.keys())
# {"jesus"}

# Uniikit analyysi 1:ss√§ (difference)
unique_1 = set(words_1.keys()) - set(words_2.keys())
# {"lord", "god"}

# Uniikit analyysi 2:ssa
unique_2 = set(words_2.keys()) - set(words_1.keys())
# {"love", "peace"}
```

**Frekvenssierot:**

```python
frequency_changes = []
for word in common:
    count1 = words_1[word]  # 120
    count2 = words_2[word]  # 150
    diff = count2 - count1  # +30

    frequency_changes.append((word, count1, count2, diff))

# J√§rjest√§ suurimmat muutokset ensin
frequency_changes.sort(key=lambda x: abs(x[3]), reverse=True)
```

**Palautusarvo:**

```python
{
    "analysis_1": {metadata...},
    "analysis_2": {metadata...},
    "common_words": [("jesus", 120, 150), ...],
    "unique_to_first": [("lord", 85), ("god", 65)],
    "unique_to_second": [("love", 60), ("peace", 40)],
    "frequency_changes": [("jesus", 120, 150, +30), ...]
}
```

---

## Tietokantaskeema

### Taulu: `analysis_history`

| Kentt√§          | Tyyppi    | Kuvaus                                       |
| --------------- | --------- | -------------------------------------------- |
| `id`            | TEXT      | Uniikki tunniste (UUID)                      |
| `user_id`       | TEXT      | Kuka teki analyysin                          |
| `session_id`    | TEXT      | Session yhteydess√§ (NULL jos ei)             |
| `analysis_type` | TEXT      | "word_frequency" / "phrase_analysis"         |
| `scope_type`    | TEXT      | "query" / "session" / "book" / "multi_query" |
| `scope_details` | TEXT      | JSON: esim `{"query_id": "abc"}`             |
| `verse_count`   | INTEGER   | Analysoitujen jakeiden m√§√§r√§                 |
| `created_at`    | TIMESTAMP | Automaattinen aikaleima                      |

### Taulu: `analysis_results`

| Kentt√§        | Tyyppi    | Kuvaus                                             |
| ------------- | --------- | -------------------------------------------------- |
| `id`          | TEXT      | Uniikki tunniste                                   |
| `analysis_id` | TEXT      | Viittaus `analysis_history.id`                     |
| `result_type` | TEXT      | "word_freq" / "vocab_stats" / "bigram" / "trigram" |
| `result_data` | TEXT      | JSON: varsinaiset tulokset                         |
| `chart_path`  | TEXT      | Polku visualisointitiedostoon (NULL jos ei)        |
| `created_at`  | TIMESTAMP | Automaattinen aikaleima                            |

### Relaatio

```
analysis_history (1) ----< (N) analysis_results
       (yksi)                    (monta)

Yksi analyysi voi sis√§lt√§√§ monta tulosta:
- Word frequency ‚Üí word_freq + vocab_stats (2 kpl)
- Phrase analysis ‚Üí bigram + trigram (2 kpl)
```

---

## K√§ytt√∂esimerkit

### Esimerkki 1: Tallenna Word Frequency

```python
from app.analytics.analysis_tracker import AnalysisTracker
from app.state import AppState

# Oletetaan k√§ytt√§j√§ kirjautunut
state = AppState()
tracker = AnalysisTracker(
    user_id=state.current_user_id,
    session_id=state.current_session_id
)

# Tallenna analyysi
analysis_id = tracker.save_word_frequency_analysis(
    word_freq=[("jesus", 120), ("lord", 85)],
    vocab_info={"total_tokens": 1500, "vocabulary_size": 450},
    scope_type="query",
    scope_details={"query_id": "abc123"},
    verse_count=25
)

print(f"Saved: {analysis_id}")  # "a3b4c5d6"
```

### Esimerkki 2: Hae Historia

```python
# Hae kaikki omat word frequency analyysit
history = tracker.get_analysis_history(
    limit=10,
    analysis_type="word_frequency"
)

for item in history:
    print(f"{item['created_at']}: {item['scope_type']} ({item['verse_count']} verses)")
```

### Esimerkki 3: Hae Yksitt√§inen Analyysi

```python
results = tracker.get_analysis_results("a3b4c5d6")

print(f"Type: {results['analysis_type']}")
print(f"Verses: {results['verse_count']}")

# Tulokset
word_freq = results["results"]["word_freq"]
print(f"Top word: {word_freq[0][0]} ({word_freq[0][1]} times)")

vocab = results["results"]["vocab_stats"]
print(f"Total tokens: {vocab['total_tokens']}")
```

### Esimerkki 4: Vertaile Analyysej√§

```python
comparison = tracker.compare_analyses("abc123", "def456")

print("\n=== YHTEISET SANAT ===")
for word, count1, count2 in comparison["common_words"]:
    print(f"{word}: {count1} ‚Üí {count2}")

print("\n=== VAIN ENSIMM√ÑISESS√Ñ ===")
for word, count in comparison["unique_to_first"]:
    print(f"{word}: {count}")

print("\n=== SUURIMMAT MUUTOKSET ===")
for word, c1, c2, diff in comparison["frequency_changes"][:5]:
    change = "+" if diff > 0 else ""
    print(f"{word}: {c1} ‚Üí {c2} ({change}{diff})")
```

---

## Debuggaus ja Troubleshooting

### Ongelma 1: "Analysis not found"

```python
results = tracker.get_analysis_results("wrong_id")
# Returns: None
```

**Ratkaisu:** Tarkista ett√§ ID on oikein

```python
history = tracker.get_analysis_history()
print([h["id"] for h in history])  # Lista kaikista ID:ist√§
```

### Ongelma 2: JSON Decode Error

```python
# Virhe: json.decoder.JSONDecodeError
```

**Syy:** Tietokannassa v√§√§rin muotoiltu JSON

**Ratkaisu:** Tarkista `result_data`:

```sql
SELECT result_data FROM analysis_results WHERE analysis_id = 'abc123';
```

### Ongelma 3: Tyhj√§ historia

```python
history = tracker.get_analysis_history()
# Returns: []
```

**Tarkista:**

1. Onko `user_id` asetettu?
2. Onko tietokannassa dataa?
   ```sql
   SELECT COUNT(*) FROM analysis_history;
   ```

### Ongelma 4: V√§√§r√§ j√§rjestys

Jos analyysit eiv√§t ole oikeassa j√§rjestyksess√§:

**Syy:** Kaikilla sama `created_at` timestamp

**Ratkaisu:** ROWID tiebreaker on jo lis√§tty:

```python
ORDER BY created_at DESC, ROWID DESC
```

### Debug Mode

```python
# Lis√§√§ loggeria
from loguru import logger

logger.add("debug.log", level="DEBUG")

# Tracker logittaa automaattisesti
tracker.save_word_frequency_analysis(...)
# Log: "Saved word frequency analysis: a3b4c5d6"
```

---

## Yhteenveto

### Avainasiat:

1. **JSON = Datan serialisointi**

   - Pythonin objektit ‚Üí String (tallennukseen)
   - String ‚Üí Pythonin objektit (luvussa)

2. **JOIN = Yhdist√§ taulut**

   - Metadata (history) + Tulokset (results)
   - LEFT JOIN = Kaikki history-rivit, vaikka ei results

3. **Set-operaatiot = Vertailu**

   - Intersection (&) = Yhteiset
   - Difference (-) = Uniikit

4. **Dynaaminen SQL = Joustavuus**

   - Rakenna query tarpeen mukaan
   - Parametrit est√§v√§t SQL-injektion

5. **ROWID = J√§rjestyksen varmistus**
   - Kun timestamp ei riit√§
   - SQLiten sis√§inen rivij√§rjestysnumero

---

## Testikattavuus

‚úÖ **31/31 testi√§ l√§p√§istiin**

- TestSaveWordFrequencyAnalysis (8 testi√§)
- TestSavePhraseAnalysis (5 testi√§)
- TestGetAnalysisHistory (5 testi√§)
- TestGetAnalysisResults (4 testi√§)
- TestCompareAnalyses (5 testi√§)
- TestEdgeCases (4 testi√§)

**Testatut skenaariot:**

- ‚úÖ Normaalit k√§ytt√∂tapaukset
- ‚úÖ Suodattimet ja rajoittimet
- ‚úÖ JSON serialisointi/deserialisointi
- ‚úÖ Virhetilanteet (NULL, tyhj√§t listat, invalid ID)
- ‚úÖ Erikoismerkit ja Unicode
- ‚úÖ Suuret datasetit (1000+ sanaa)

---

**Viimeksi p√§ivitetty:** 2026-01-15  
**Tekij√§:** AI Assistant + vvirtai  
**Tiedosto:** `app/analytics/analysis_tracker.py`
